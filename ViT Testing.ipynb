{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 1. Set Up the Environment\n",
    "Download specific libraries to access the model like torch, torchvision and transformers through !pip\n"
   ],
   "id": "759f8cdaeb164991"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:29:04.478559Z",
     "start_time": "2025-07-12T09:28:54.989183Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128\n",
    "!pip install transformers scikit-learn pillow pandas numpy\n",
    "!pip install opencv-python"
   ],
   "id": "70a3781b7bb98718",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu128\n",
      "Requirement already satisfied: torch in c:\\users\\aloys\\anaconda3\\lib\\site-packages (2.7.1+cu128)\n",
      "Requirement already satisfied: torchvision in c:\\users\\aloys\\anaconda3\\lib\\site-packages (0.22.1+cu128)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\aloys\\anaconda3\\lib\\site-packages (2.7.1+cu128)\n",
      "Requirement already satisfied: filelock in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from torch) (72.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from torchvision) (2.1.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: transformers in c:\\users\\aloys\\anaconda3\\lib\\site-packages (4.53.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\aloys\\anaconda3\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\aloys\\anaconda3\\lib\\site-packages (11.1.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\aloys\\anaconda3\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\aloys\\anaconda3\\lib\\site-packages (2.1.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from transformers) (0.33.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from scikit-learn) (1.15.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.4.26)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\aloys\\anaconda3\\lib\\site-packages (4.12.0.88)\n",
      "Requirement already satisfied: numpy<2.3.0,>=2 in c:\\users\\aloys\\anaconda3\\lib\\site-packages (from opencv-python) (2.1.3)\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Import Libraries\n",
    "Import necessary libraries to test the model without any issues"
   ],
   "id": "7a636a053fde2e34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:29:04.496011Z",
     "start_time": "2025-07-12T09:29:04.489334Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch # Pytorch to run ViT model\n",
    "import torch.nn as nn # Pytorch neural network libraries\n",
    "from torchvision import datasets, transforms # Load the dataset\n",
    "from torch.utils.data import DataLoader, Dataset # Load the dataset\n",
    "from torch.optim import AdamW # Optimizer\n",
    "import torch.nn.functional as F # Provide functions like softmax to get the class probabilities\n",
    "from transformers import ViTModel, AutoImageProcessor\n",
    "import torchvision.models as models\n",
    "from PIL import Image # Library required to modify image dataset\n",
    "import pandas as pd # To convert text file into label mapping\n",
    "import numpy as np # Matrix operation\n",
    "import os\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Cuda available: {torch.cuda.is_available()}\")"
   ],
   "id": "458d44333b110eff",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cuda available: True\n"
     ]
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 3. Install gdown and download folders\n",
    "Download weights, labels and test folder from google drive through gdown\n"
   ],
   "id": "176d598208eca811"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:29:29.529776Z",
     "start_time": "2025-07-12T09:29:04.666652Z"
    }
   },
   "cell_type": "code",
   "source": [
    "!pip install -q gdown\n",
    "import gdown # Library to download file from google drive\n",
    "\n",
    "model_folder_id = '1eoFx15MLxDo-8Kd-JvIcVLazSVf2j0lq' # Google drive folder id\n",
    "gdown.download_folder(id=model_folder_id, output=\"model\", quiet=False, use_cookies=False) # Download model weights and labels.txt"
   ],
   "id": "fc26a3730651f138",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 1BYkfKnKRW7R5efKWTbK97Ie-nPIIAaS1 vit_full_weights_new2_10.pth\n",
      "Processing file 1p8KG38pMPPImepVCsK2fCLhHljJ79fj- labels.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1BYkfKnKRW7R5efKWTbK97Ie-nPIIAaS1\n",
      "From (redirected): https://drive.google.com/uc?id=1BYkfKnKRW7R5efKWTbK97Ie-nPIIAaS1&confirm=t&uuid=490ea331-9ba8-47f7-9c9f-4d11546ea566\n",
      "To: C:\\Users\\aloys\\PycharmProjects\\NAIC Competition\\model\\vit_full_weights_new2_10.pth\n",
      "100%|██████████| 347M/347M [00:16<00:00, 21.4MB/s] \n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1p8KG38pMPPImepVCsK2fCLhHljJ79fj-\n",
      "To: C:\\Users\\aloys\\PycharmProjects\\NAIC Competition\\model\\labels.txt\n",
      "100%|██████████| 132/132 [00:00<00:00, 381kB/s]\n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model\\\\vit_full_weights_new2_10.pth', 'model\\\\labels.txt']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:29:50.366374Z",
     "start_time": "2025-07-12T09:29:29.540704Z"
    }
   },
   "cell_type": "code",
   "source": [
    "test_folder_id = '1LZIhiV9l82W4fNpfaBHyGvh8XBX6SoU2' # Google drive testing folder id\n",
    "gdown.download_folder(id=test_folder_id, output=\"test_folder\", quiet=False, use_cookies=False) # Download testing images"
   ],
   "id": "2a09612a51010788",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file 12ufiwhl6whVp33F05RLiDRieRSN13XlP test_labels.txt\n",
      "Retrieving folder 1qO-cQtRdp-hLu6LMQ68OEv0zA791puJO test_images\n",
      "Processing file 1cxftTp4A1_13gWe4QeAlhK9AcGzIDBEH Kek Lapis.jpg\n",
      "Processing file 17CPxIkfU_tecxiF1-G4nXTD0Vv_1biB- Kuih Seri Muka.png\n",
      "Processing file 1qTcPAX5eSPLkAkhlyGfgooDXHZPFoJOM Kuih Lapis.jpg\n",
      "Processing file 1KmI2JRpz4DnCAmPbCWoK31BJBH4ax8i7 Kuih Ubi Kayu.jpg\n",
      "Processing file 1aqVkDJiANm0MqLeTJALC1RuKZgt0IlI4 Kuih Kaswi Pandan.jpg\n",
      "Processing file 1MEhhjAoBK66wtj6Xs1orsrA2vR9qLjhR Kuih Talam.jpg\n",
      "Processing file 11K7Hc9nt3Qllw4lG4ajxineVHvXKmuY6 Kuih Ketayap.jpg\n",
      "Processing file 1QFZdtM4ok-vH0kPgA7gdZQzT1aSppWcF Onde-Onde.jpg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrieving folder contents completed\n",
      "Building directory structure\n",
      "Building directory structure completed\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=12ufiwhl6whVp33F05RLiDRieRSN13XlP\n",
      "To: C:\\Users\\aloys\\PycharmProjects\\NAIC Competition\\test_folder\\test_labels.txt\n",
      "100%|██████████| 283/283 [00:00<00:00, 448kB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1cxftTp4A1_13gWe4QeAlhK9AcGzIDBEH\n",
      "To: C:\\Users\\aloys\\PycharmProjects\\NAIC Competition\\test_folder\\test_images\\Kek Lapis.jpg\n",
      "100%|██████████| 1.27M/1.27M [00:00<00:00, 17.2MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=17CPxIkfU_tecxiF1-G4nXTD0Vv_1biB-\n",
      "To: C:\\Users\\aloys\\PycharmProjects\\NAIC Competition\\test_folder\\test_images\\Kuih Seri Muka.png\n",
      "100%|██████████| 1.04M/1.04M [00:00<00:00, 15.8MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1qTcPAX5eSPLkAkhlyGfgooDXHZPFoJOM\n",
      "To: C:\\Users\\aloys\\PycharmProjects\\NAIC Competition\\test_folder\\test_images\\Kuih Lapis.jpg\n",
      "100%|██████████| 56.6k/56.6k [00:00<00:00, 3.63MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1KmI2JRpz4DnCAmPbCWoK31BJBH4ax8i7\n",
      "To: C:\\Users\\aloys\\PycharmProjects\\NAIC Competition\\test_folder\\test_images\\Kuih Ubi Kayu.jpg\n",
      "100%|██████████| 155k/155k [00:00<00:00, 4.68MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1aqVkDJiANm0MqLeTJALC1RuKZgt0IlI4\n",
      "To: C:\\Users\\aloys\\PycharmProjects\\NAIC Competition\\test_folder\\test_images\\Kuih Kaswi Pandan.jpg\n",
      "100%|██████████| 418k/418k [00:00<00:00, 9.20MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1MEhhjAoBK66wtj6Xs1orsrA2vR9qLjhR\n",
      "To: C:\\Users\\aloys\\PycharmProjects\\NAIC Competition\\test_folder\\test_images\\Kuih Talam.jpg\n",
      "100%|██████████| 16.8k/16.8k [00:00<00:00, 5.08MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=11K7Hc9nt3Qllw4lG4ajxineVHvXKmuY6\n",
      "To: C:\\Users\\aloys\\PycharmProjects\\NAIC Competition\\test_folder\\test_images\\Kuih Ketayap.jpg\n",
      "100%|██████████| 373k/373k [00:00<00:00, 7.02MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1QFZdtM4ok-vH0kPgA7gdZQzT1aSppWcF\n",
      "To: C:\\Users\\aloys\\PycharmProjects\\NAIC Competition\\test_folder\\test_images\\Onde-Onde.jpg\n",
      "100%|██████████| 95.9k/95.9k [00:00<00:00, 6.39MB/s]\n",
      "Download completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['test_folder\\\\test_labels.txt',\n",
       " 'test_folder\\\\test_images\\\\Kek Lapis.jpg',\n",
       " 'test_folder\\\\test_images\\\\Kuih Seri Muka.png',\n",
       " 'test_folder\\\\test_images\\\\Kuih Lapis.jpg',\n",
       " 'test_folder\\\\test_images\\\\Kuih Ubi Kayu.jpg',\n",
       " 'test_folder\\\\test_images\\\\Kuih Kaswi Pandan.jpg',\n",
       " 'test_folder\\\\test_images\\\\Kuih Talam.jpg',\n",
       " 'test_folder\\\\test_images\\\\Kuih Ketayap.jpg',\n",
       " 'test_folder\\\\test_images\\\\Onde-Onde.jpg']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 4. Load ViT Model\n",
    "Setting up ViT transformers by adjusting its inner architecture and initialise it"
   ],
   "id": "6899022fff811710"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:29:50.481173Z",
     "start_time": "2025-07-12T09:29:50.471221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class ViTForClassification(nn.Module): # Define the Vision Transformers Model, creating a framework to create ViT model based on its adjustments\n",
    "    def __init__(self, vit_model, num_classes=8):\n",
    "        super().__init__()\n",
    "        self.vit = vit_model\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(self.vit.config.hidden_size, 512), # Fully Connected Network have 512 neurons\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(), # ReLu activation function\n",
    "            nn.Dropout(0.3), # Dropout to randomly delete neurons to reduce overfitting\n",
    "            nn.Linear(512, num_classes), # Fully Connected Network from 512 neurons map to 8 classes\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.vit(pixel_values=x)\n",
    "        cls_token = outputs.last_hidden_state[:, 0, :] # Modify the token from the transformers\n",
    "        return self.classifier(cls_token)\n",
    "\n",
    "def get_vit_model(num_classes):\n",
    "    vit_model = ViTModel.from_pretrained('google/vit-base-patch16-224') # Get the base pretrained ViT model from google\n",
    "    return ViTForClassification(vit_model, num_classes) # Match the vit_model output to number of classes\n",
    "\n",
    "class ViTEnsembleModel(nn.Module):\n",
    "    def __init__(self, vit_path):\n",
    "        super().__init__()\n",
    "        self.softmax = nn.Softmax(dim=0) # Provide softmax function\n",
    "\n",
    "        self.vit = get_vit_model(8) # Output vit model final layer to 8 classes\n",
    "        self.vit.load_state_dict(torch.load(vit_path, map_location=device)) # Load the ViT model weights\n",
    "        self.vit = self.vit.to(device) # Attach vit model to a device(either cpu or gpu)\n",
    "        self.vit.eval() # Evaluate the vit model, which is to run in testing mode.\n",
    "\n",
    "    def forward(self, x):\n",
    "        with torch.no_grad():\n",
    "            vit_outputs = self.vit(x) # Forward propagation from fully connected network with 512 neurons to final 8 classes\n",
    "\n",
    "        return vit_outputs"
   ],
   "id": "c18f7a2fa4162a7f",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:31:21.947297Z",
     "start_time": "2025-07-12T09:31:19.462513Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Optimizing VIT weights...\")\n",
    "vit_path = 'model/vit_full_weights_new2_10.pth' # Set model weight path\n",
    "vit = ViTEnsembleModel(vit_path).to(device) # Create ViT model based on ViTEnsembleModel class just now\n",
    "optimizer = AdamW(vit.parameters(), lr=3e-5) # set optimizer and adjust the learning rate to 0.00003"
   ],
   "id": "1b1e52b1b32b66aa",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing VIT weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ViTModel were not initialized from the model checkpoint at google/vit-base-patch16-224 and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 5. Load labels.txt",
   "id": "3b1cdf7cbfa66bd8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:31:24.572845Z",
     "start_time": "2025-07-12T09:31:24.563282Z"
    }
   },
   "cell_type": "code",
   "source": [
    "## Change this to where your labels.txt is\n",
    "labels_filename = 'model/labels.txt'   ##changes here in v2 to point to /content/model\n",
    "labels = {}\n",
    "with open(labels_filename, 'r') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            idx, label = line.strip().split(': ', 1)\n",
    "            # idx only include the value before :, like 0: Kuih Talam split into 0\n",
    "            # label only include the value after :, like 0: Kuih Talam split into Kuih Talam\n",
    "            labels[int(idx)] = label # exp: labels[0] = Kuih Talam\n",
    "\n",
    "label_to_class_index = {v: k for k, v in labels.items()}  # {class_name: index} # Use list function to map label into the index, like 0: Kuih Talam\n",
    "index_to_label = {k: v for k, v in labels.items()}        # {index: class_name} # Use list function to map index to label, like Kuih Talam :0\n",
    "print(f\"Loaded {len(labels)} classes:\")\n",
    "for idx, label in labels.items():\n",
    "    print(f\"  {idx}: {label}\")\n",
    "print(labels)"
   ],
   "id": "cdb8013b8927f2bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 8 classes:\n",
      "  0: Kek Lapis\n",
      "  1: Kuih Kaswi Pandan\n",
      "  2: Kuih Ketayap\n",
      "  3: Kuih Lapis\n",
      "  4: Kuih Seri Muka\n",
      "  5: Kuih Talam\n",
      "  6: Kuih Ubi Kayu\n",
      "  7: Onde-Onde\n",
      "{0: 'Kek Lapis', 1: 'Kuih Kaswi Pandan', 2: 'Kuih Ketayap', 3: 'Kuih Lapis', 4: 'Kuih Seri Muka', 5: 'Kuih Talam', 6: 'Kuih Ubi Kayu', 7: 'Onde-Onde'}\n"
     ]
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6a. Accessing Testing Directories\n",
   "id": "853fd21ffa0d6d0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:31:26.690571Z",
     "start_time": "2025-07-12T09:31:26.684445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Get list of test images\n",
    "test_dir = 'test_folder/test_images'  ##changes here in v2 to point to /content/model\n",
    "test_images = []\n",
    "for root, _, files in os.walk(test_dir):\n",
    "    for file in files:\n",
    "        if file.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            test_images.append(os.path.join(root, file)) # Add the image into the file\n",
    "\n",
    "test_images.sort()  # Sort to ensure consistent order\n",
    "print(f\"Found {len(test_images)} test images\")"
   ],
   "id": "adca44f5a2b4685a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 test images\n"
     ]
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# 6b. Ensure label correctness",
   "id": "fd26e662d251174"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:31:28.667136Z",
     "start_time": "2025-07-12T09:31:28.654117Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_test = pd.read_csv('test_folder/test_labels.txt')\n",
    "\n",
    "# Clean class labels: remove trailing digits (like \"Kuih Talam 1\"), and strip spaces\n",
    "df_test['Class'] = df_test['Class'].str.replace(r'\\s*\\d+$', '', regex=True).str.strip()\n",
    "\n",
    "# Validation\n",
    "test_class_names = set(df_test['Class'].unique())\n",
    "for class_name in test_class_names:\n",
    "    if class_name not in label_to_class_index:\n",
    "        print(f\"Error: Class '{class_name}' in test set is not present in labels.txt\")\n",
    "        raise ValueError(\"Test set contains unknown classes\")\n",
    "print(\"All test classes are present in labels.txt\")\n",
    "\n",
    "# Create lookup dict\n",
    "test_labels = dict(zip(df_test['Filename'].str.strip(), df_test['Class'].str.strip()))\n",
    "filename_to_class = test_labels.copy()"
   ],
   "id": "71e99b4495d21ad5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All test classes are present in labels.txt\n"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 7. CSV Converter\n",
    "Convert test folder images into csv file\n"
   ],
   "id": "2482927d068e6c3d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:31:31.026405Z",
     "start_time": "2025-07-12T09:31:30.428527Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import glob\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "testing_image_folder = Path(\"test_folder/test_images\")\n",
    "testing_csv_file = \"test.csv\"\n",
    "image_size = (224, 224)\n",
    "\n",
    "def clean_label_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Example: 'Kek Lapis 2.jpg' → 'Kek Lapis'\n",
    "    \"\"\"\n",
    "    name = os.path.splitext(filename)[0]              # remove .jpg\n",
    "    label = re.sub(r'\\s*\\d+$', '', name).strip()      # remove trailing number\n",
    "    return label\n",
    "\n",
    "\n",
    "def write_dataset_to_csv(image_folder, csv_file):\n",
    "    # Include different type of images like jpg, jpeg and png\n",
    "    # If there's different type of image file type please help add it below the image_files based on the pattern. Thanks!\n",
    "    image_files = list(image_folder.glob(\"*.jpg\")) + \\\n",
    "                  list(image_folder.glob(\"*.jpeg\")) + \\\n",
    "                  list(image_folder.glob(\"*.png\")) + \\\n",
    "                  list(image_folder.glob(\"*.WebP\"))\n",
    "\n",
    "    with open(csv_file, 'w', newline='') as csvfile:\n",
    "        csv_writer = csv.writer(csvfile)\n",
    "        csv_writer.writerow([\"filename\", \"label\", \"pixels\"])  # Added filename column\n",
    "\n",
    "        for image_file in image_files:\n",
    "            try:\n",
    "                image = cv2.imread(image_file)\n",
    "                if image is None:\n",
    "                    print(f\"Error reading image {image_file}\")\n",
    "                    continue\n",
    "\n",
    "                image = cv2.resize(image, image_size)\n",
    "                image_array = np.array(image).flatten()\n",
    "                image_data_str = ','.join(map(str, image_array))\n",
    "\n",
    "                filename = os.path.basename(image_file)\n",
    "                label = clean_label_from_filename(filename)\n",
    "\n",
    "                csv_writer.writerow([filename, label, image_data_str])  # Store original filename\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_file}: {e}\")\n",
    "\n",
    "write_dataset_to_csv(testing_image_folder, testing_csv_file)\n",
    "print(f\"CSV file '{testing_csv_file}' created successfully.\")\n",
    "\n",
    "df = pd.read_csv('test.csv')\n",
    "print(f\"CSV contains {len(df)} rows\")\n",
    "print(\"Missing images:\", set(os.path.basename(p) for p in test_images) - set(df['filename']))\n"
   ],
   "id": "58349edcaddba0d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file 'test.csv' created successfully.\n",
      "CSV contains 8 rows\n",
      "Missing images: set()\n"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 8. Data Loader\n",
    "Load dataset from csv file"
   ],
   "id": "610198340f81c659"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:31:33.910541Z",
     "start_time": "2025-07-12T09:31:33.898700Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DataSetLoader(Dataset):\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "        # Check for required columns\n",
    "        if 'pixels' not in self.data.columns or 'label' not in self.data.columns:\n",
    "            raise ValueError(\"CSV must contain 'pixels' and 'label' columns.\")\n",
    "\n",
    "        # Drop rows with missing values\n",
    "        self.data.dropna(subset=['pixels', 'label'], inplace=True)\n",
    "\n",
    "        # Create label map\n",
    "        unique_labels = sorted(self.data['label'].unique())\n",
    "        self.label_map = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        self.num_classes = len(self.label_map)\n",
    "\n",
    "        # Store original filenames if available (optional)\n",
    "        if 'filename' in self.data.columns:\n",
    "            self.filenames = self.data['filename'].values\n",
    "        else:\n",
    "            self.filenames = None\n",
    "\n",
    "        print(f\"[INFO] Loaded {len(self.data)} samples with {self.num_classes} unique classes.\")\n",
    "        print(f\"[INFO] Label map: {self.label_map}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "      # Decode pixel string into image array\n",
    "      pixel_str = self.data.iloc[idx]['pixels']\n",
    "      image_flat = np.fromstring(pixel_str, sep=',', dtype=np.uint8)\n",
    "\n",
    "      try:\n",
    "          image = image_flat.reshape((224, 224, 3))\n",
    "      except ValueError:\n",
    "          raise ValueError(f\"Image at index {idx} could not be reshaped. Array shape: {image_flat.shape}\")\n",
    "\n",
    "      image = Image.fromarray(image)\n",
    "\n",
    "      # Get the string label and convert to integer using label_map\n",
    "      str_label = self.data.iloc[idx]['label']\n",
    "      label = self.label_map[str_label]  # This gives us the integer label\n",
    "      label = torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "      # Get filename (either from CSV or generate it)\n",
    "      if self.filenames is not None:\n",
    "          filename = self.filenames[idx]\n",
    "      else:\n",
    "          filename = f\"{str_label}.jpg\"\n",
    "\n",
    "      if self.transform:\n",
    "          image = self.transform(image)\n",
    "\n",
    "      return image, label, filename\n",
    "\n",
    "    def get_class_names(self):\n",
    "        \"\"\"Returns list of class names in order of their indices\"\"\"\n",
    "        return sorted(self.label_map.keys(), key=lambda x: self.label_map[x])\n",
    "\n"
   ],
   "id": "126f839178e84985",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 9. Running Predictions\n",
    "Testing phase"
   ],
   "id": "6d1d89d808d94e57"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:31:39.391313Z",
     "start_time": "2025-07-12T09:31:37.678525Z"
    }
   },
   "cell_type": "code",
   "source": [
    "predictions = []\n",
    "processor = AutoImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
    "\n",
    "# Data preprocessing\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=processor.image_mean, std=processor.image_std)\n",
    "])\n",
    "\n",
    "test_dataset = DataSetLoader('test.csv', test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "print(test_dataset.label_map)\n",
    "\n",
    "\n",
    "index_to_label = {v: k for k, v in test_dataset.label_map.items()}\n",
    "label_to_class_index = {v: k for k, v in index_to_label.items()}\n",
    "print(\"Index to label: \", index_to_label)\n",
    "print(\"Label to index: \", label_to_class_index)\n",
    "print(\"Full label map:\", test_dataset.label_map)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels, filenames in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        outputs = vit(images)\n",
    "        probabilities = F.softmax(outputs, dim=1)\n",
    "        predicted_indices = torch.argmax(probabilities, dim=1)\n",
    "\n",
    "        for i in range(len(images)):\n",
    "            filename = filenames[i]\n",
    "            pred_idx = predicted_indices[i].item()\n",
    "            actual_idx = labels[i].item()\n",
    "            pred_label = index_to_label.get(pred_idx, f\"unknown_class_{pred_idx}\")\n",
    "            actual_label = index_to_label[actual_idx]\n",
    "            class_probs = probabilities[i].cpu().numpy()\n",
    "\n",
    "            # Store prediction result\n",
    "            predictions.append({\n",
    "                'image': filename,\n",
    "                'predicted_class_index': pred_idx,\n",
    "                'predicted_label': pred_label,\n",
    "                'class_probabilities': class_probs.tolist()  # convert to list for JSON-safe export\n",
    "            })"
   ],
   "id": "16cac36d51c53f34",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Loaded 8 samples with 8 unique classes.\n",
      "[INFO] Label map: {'Kek Lapis': 0, 'Kuih Kaswi Pandan': 1, 'Kuih Ketayap': 2, 'Kuih Lapis': 3, 'Kuih Seri Muka': 4, 'Kuih Talam': 5, 'Kuih Ubi Kayu': 6, 'Onde-Onde': 7}\n",
      "{'Kek Lapis': 0, 'Kuih Kaswi Pandan': 1, 'Kuih Ketayap': 2, 'Kuih Lapis': 3, 'Kuih Seri Muka': 4, 'Kuih Talam': 5, 'Kuih Ubi Kayu': 6, 'Onde-Onde': 7}\n",
      "Index to label:  {0: 'Kek Lapis', 1: 'Kuih Kaswi Pandan', 2: 'Kuih Ketayap', 3: 'Kuih Lapis', 4: 'Kuih Seri Muka', 5: 'Kuih Talam', 6: 'Kuih Ubi Kayu', 7: 'Onde-Onde'}\n",
      "Label to index:  {'Kek Lapis': 0, 'Kuih Kaswi Pandan': 1, 'Kuih Ketayap': 2, 'Kuih Lapis': 3, 'Kuih Seri Muka': 4, 'Kuih Talam': 5, 'Kuih Ubi Kayu': 6, 'Onde-Onde': 7}\n",
      "Full label map: {'Kek Lapis': 0, 'Kuih Kaswi Pandan': 1, 'Kuih Ketayap': 2, 'Kuih Lapis': 3, 'Kuih Seri Muka': 4, 'Kuih Talam': 5, 'Kuih Ubi Kayu': 6, 'Onde-Onde': 7}\n"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 10. Creating Outputs\n",
    "Printing output using pandas library"
   ],
   "id": "632412e53eafdd96"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:31:41.995627Z",
     "start_time": "2025-07-12T09:31:41.971662Z"
    }
   },
   "cell_type": "code",
   "source": [
    "results_df = pd.DataFrame(predictions)\n",
    "display(results_df)"
   ],
   "id": "e6dabf2660118e2a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   image  predicted_class_index    predicted_label  \\\n",
       "0          Kek Lapis.jpg                      0          Kek Lapis   \n",
       "1  Kuih Kaswi Pandan.jpg                      1  Kuih Kaswi Pandan   \n",
       "2       Kuih Ketayap.jpg                      2       Kuih Ketayap   \n",
       "3         Kuih Lapis.jpg                      3         Kuih Lapis   \n",
       "4         Kuih Talam.jpg                      5         Kuih Talam   \n",
       "5      Kuih Ubi Kayu.jpg                      6      Kuih Ubi Kayu   \n",
       "6          Onde-Onde.jpg                      7          Onde-Onde   \n",
       "7     Kuih Seri Muka.png                      4     Kuih Seri Muka   \n",
       "\n",
       "                                 class_probabilities  \n",
       "0  [0.9200485348701477, 0.010303686372935772, 0.0...  \n",
       "1  [0.01865220069885254, 0.8201457262039185, 0.01...  \n",
       "2  [0.011439827270805836, 0.01115582324564457, 0....  \n",
       "3  [0.007907097227871418, 0.009971368126571178, 0...  \n",
       "4  [0.00497874990105629, 0.006190862040966749, 0....  \n",
       "5  [0.008483816869556904, 0.010306216776371002, 0...  \n",
       "6  [0.011046474799513817, 0.011978148482739925, 0...  \n",
       "7  [0.019940165802836418, 0.0636836513876915, 0.0...  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>predicted_class_index</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>class_probabilities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kek Lapis.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>Kek Lapis</td>\n",
       "      <td>[0.9200485348701477, 0.010303686372935772, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kuih Kaswi Pandan.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>Kuih Kaswi Pandan</td>\n",
       "      <td>[0.01865220069885254, 0.8201457262039185, 0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kuih Ketayap.jpg</td>\n",
       "      <td>2</td>\n",
       "      <td>Kuih Ketayap</td>\n",
       "      <td>[0.011439827270805836, 0.01115582324564457, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kuih Lapis.jpg</td>\n",
       "      <td>3</td>\n",
       "      <td>Kuih Lapis</td>\n",
       "      <td>[0.007907097227871418, 0.009971368126571178, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kuih Talam.jpg</td>\n",
       "      <td>5</td>\n",
       "      <td>Kuih Talam</td>\n",
       "      <td>[0.00497874990105629, 0.006190862040966749, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Kuih Ubi Kayu.jpg</td>\n",
       "      <td>6</td>\n",
       "      <td>Kuih Ubi Kayu</td>\n",
       "      <td>[0.008483816869556904, 0.010306216776371002, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Onde-Onde.jpg</td>\n",
       "      <td>7</td>\n",
       "      <td>Onde-Onde</td>\n",
       "      <td>[0.011046474799513817, 0.011978148482739925, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kuih Seri Muka.png</td>\n",
       "      <td>4</td>\n",
       "      <td>Kuih Seri Muka</td>\n",
       "      <td>[0.019940165802836418, 0.0636836513876915, 0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 11. Metrics Computation\n",
    "Calculate the accuracy, precision, recall, F1 and ROC-AUC of the output result"
   ],
   "id": "a3828d22e1d11398"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:31:45.771898Z",
     "start_time": "2025-07-12T09:31:45.757536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "\n",
    "# Re-read and preprocess test_labels.txt\n",
    "df_test = pd.read_csv('test_folder/test_labels.txt')\n",
    "df_test['Class'] = df_test['Class'].str.replace(r'\\s*\\d+$', '', regex=True).str.strip()\n",
    "df_test['Filename'] = df_test['Filename'].str.strip()\n",
    "\n",
    "# Build filename_to_class from test labels\n",
    "filename_to_class = dict(zip(df_test['Filename'], df_test['Class']))\n",
    "\n",
    "# Assume labels is already defined\n",
    "label_to_class_index = {v.strip(): k for k, v in index_to_label.items()}\n",
    "\n",
    "# ✅ Updated function: extract class name from filename\n",
    "def extract_class_from_filename(filename):\n",
    "    name_part = os.path.splitext(filename)[0]  # e.g., 'Kek Lapis 1'\n",
    "    name_part = re.sub(r'\\s*\\d+$', '', name_part)  # Remove trailing numbers\n",
    "    return name_part.strip()\n",
    "\n",
    "# Create true_class_index from only the filenames that were processed\n",
    "true_class_index = []\n",
    "\n",
    "for filename in results_df['image']:\n",
    "    filename = filename.strip()\n",
    "    class_name = extract_class_from_filename(filename)\n",
    "\n",
    "    if class_name not in label_to_class_index:\n",
    "        raise ValueError(f\"Unknown class '{class_name}' extracted from filename '{filename}'\")\n",
    "\n",
    "    true_class_index.append(label_to_class_index[class_name])\n",
    "\n",
    "print(\"True class index: \", true_class_index)\n"
   ],
   "id": "2420dd8b0700a047",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True class index:  [0, 1, 2, 3, 5, 6, 7, 4]\n"
     ]
    }
   ],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:31:49.507668Z",
     "start_time": "2025-07-12T09:31:49.496326Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import (\n",
    "    classification_report, accuracy_score,\n",
    "    roc_auc_score, precision_recall_fscore_support\n",
    ")\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "results_df['true_class_index'] = true_class_index  ## changes here in v2 - refer to true_class_index\n",
    "y_true = results_df['true_class_index'].astype(int).values\n",
    "y_pred = results_df['predicted_class_index'].astype(int).values\n",
    "\n",
    "print(y_true)\n",
    "print(y_pred)\n",
    "\n",
    "## Quick fix for ROC Curve as I only have 3 classes here (DO NOT NEED THIS IF YOU HAVE 8 CLASSES IN YOUR TEST SET)\n",
    "FULL_NUM_CLASSES = 8  # total number of possible classes\n",
    "\n",
    "# ✅ Fix: Pad each probability list to 8 elements\n",
    "def pad_probs(probs, target_len=FULL_NUM_CLASSES):\n",
    "    probs = np.ravel(probs)  # Ensure 1D\n",
    "    padded = np.zeros(target_len)\n",
    "    padded[:len(probs)] = probs  # Assumes order is correct\n",
    "    return padded\n",
    "\n",
    "# ✅ Apply padding safely\n",
    "y_probs_padded = np.array([pad_probs(p) for p in results_df['class_probabilities']])\n",
    "y_probs = y_probs_padded  # Now it's safe\n"
   ],
   "id": "398e855bdbcc4c22",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 5 6 7 4]\n",
      "[0 1 2 3 5 6 7 4]\n"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-12T09:31:52.932977Z",
     "start_time": "2025-07-12T09:31:52.895578Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Number of classes\n",
    "n_classes = FULL_NUM_CLASSES\n",
    "class_names = list(range(FULL_NUM_CLASSES))\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "print(f\"\\n✅ Accuracy: {acc:.4f}\")\n",
    "\n",
    "# Precision, Recall, F1 per class & macro\n",
    "prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, labels=class_names, average=None)\n",
    "macro_prec, macro_rec, macro_f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro')\n",
    "\n",
    "print(\"\\n📊 Per-class metrics:\")\n",
    "for i, cls in enumerate(class_names):\n",
    "    print(f\"Class {cls}: Precision={prec[i]:.4f}, Recall={rec[i]:.4f}, F1={f1[i]:.4f}\")\n",
    "\n",
    "print(f\"\\n📦 Macro Precision: {macro_prec:.4f}, Macro Recall: {macro_rec:.4f}, Macro F1: {macro_f1:.4f}\")\n",
    "\n",
    "# ROC AUC (requires binarized labels)\n",
    "y_true_bin = label_binarize(y_true, classes=class_names)\n",
    "\n",
    "# ROC AUC per class and macro\n",
    "try:\n",
    "    auc_per_class = roc_auc_score(y_true_bin, y_probs, average=None, multi_class='ovr')\n",
    "    auc_macro = roc_auc_score(y_true_bin, y_probs, average='macro', multi_class='ovr')\n",
    "\n",
    "    print(\"\\n🎯 ROC AUC per class:\")\n",
    "    for i, cls in enumerate(class_names):\n",
    "        print(f\"Class {cls}: AUC = {auc_per_class[i]:.4f}\")\n",
    "\n",
    "    print(f\"\\n🌐 Macro ROC AUC: {auc_macro:.4f}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"⚠️ ROC AUC could not be computed: {e}\")\n"
   ],
   "id": "650cce92dd40cea1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Accuracy: 1.0000\n",
      "\n",
      "📊 Per-class metrics:\n",
      "Class 0: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class 1: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class 2: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class 3: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class 4: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class 5: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class 6: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "Class 7: Precision=1.0000, Recall=1.0000, F1=1.0000\n",
      "\n",
      "📦 Macro Precision: 1.0000, Macro Recall: 1.0000, Macro F1: 1.0000\n",
      "\n",
      "🎯 ROC AUC per class:\n",
      "Class 0: AUC = 1.0000\n",
      "Class 1: AUC = 1.0000\n",
      "Class 2: AUC = 1.0000\n",
      "Class 3: AUC = 1.0000\n",
      "Class 4: AUC = 1.0000\n",
      "Class 5: AUC = 1.0000\n",
      "Class 6: AUC = 1.0000\n",
      "Class 7: AUC = 1.0000\n",
      "\n",
      "🌐 Macro ROC AUC: 1.0000\n"
     ]
    }
   ],
   "execution_count": 56
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
